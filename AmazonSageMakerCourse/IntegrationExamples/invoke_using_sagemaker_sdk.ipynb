{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke SageMaker Enpoint from outside of AWS environment using SageMaker SDK\n",
    "\n",
    "Model used: XGBoost Bike Rental Prediction Trained in the XGBoost Lectures  \n",
    "  \n",
    "This example uses the IAM user: ml_user_predict. The user was setup in the housekeeping lecture of the course.  \n",
    "\n",
    "Refer to the lecture: Configure IAM Users, Setup Command Line Interface (CLI)\n",
    "\n",
    "Ensure xgboost-biketrain-v1 Endpoint is deployed before running this example  \n",
    "  \n",
    "To create an endpoint using SageMaker Console:  \n",
    "1. Select \"Models\" under \"Inference\" in navigation pane\n",
    "2. Search for model using this prefix: xgboost-biketrain-v1\n",
    "3. Select the latest model and choose create endpoint\n",
    "4. Specify endpoint name as: xgboost-biketrain-v1\n",
    "5. Create a new endpoint configuration\n",
    "6. Create a new endpoint\n",
    "7. After this lab is completed, delete the endpoint to avoid unnecessary charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SageMaker 2.x version.\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import math\n",
    "import dateutil\n",
    "\n",
    "# SDK 2 serializers and deserializers\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a session with AWS\n",
    "# Specify credentials and region to be used for this session.\n",
    "# We will use a ml_user_predict credentials that has limited privileges\n",
    "boto_session = boto3.Session(profile_name='ml_user_predict',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto_session=boto_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictor and point to an existing endpoint\n",
    "\n",
    "# Get Predictor using SageMaker SDK\n",
    "# Specify Your Endpoint Name\n",
    "endpoint_name = 'xgboost-biketrain-v1'\n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name,\n",
    "                                                 sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are sending data for inference in CSV format\n",
    "predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed\n",
    "# Actual=562\n",
    "sample_one = '2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027'\n",
    "# Actual=569\n",
    "sample_two = '2012-12-19 18:00:00,4,0,1,1,15.58,19.695,50,23.9994'\n",
    "# Actual=4\n",
    "sample_three = '2012-12-10 01:00:00,4,0,1,2,14.76,18.94,100,0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Structure: \n",
    "# datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "\n",
    "# Model expects data in this format (it was trained with these features):\n",
    "# season,holiday,workingday,weather,temp,atemp,humidity,windspeed,year,month,day,dayofweek,hour\n",
    "\n",
    "def transform_data(data):\n",
    "    features = data.split(',')\n",
    "    \n",
    "    # Extract year, month, day, dayofweek, hour\n",
    "    dt = dateutil.parser.parse(features[0])\n",
    "\n",
    "    features.append(str(dt.year))\n",
    "    features.append(str(dt.month))\n",
    "    features.append(str(dt.day))\n",
    "    features.append(str(dt.weekday()))\n",
    "    features.append(str(dt.hour))\n",
    "    \n",
    "    # Return the transformed data. skip datetime field\n",
    "    return ','.join(features[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      " 2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027\n",
      "Transformed Data:\n",
      " 4,0,1,1,16.4,20.455,50,26.0027,2012,12,19,2,17\n"
     ]
    }
   ],
   "source": [
    "print('Raw Data:\\n',sample_one)\n",
    "print('Transformed Data:\\n',transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'6.349300861358643'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's invoke prediction now\n",
    "predictor.predict(transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count 571.092597122044\n"
     ]
    }
   ],
   "source": [
    "# Actual Count is 562...but predicted is 6.3.\n",
    "\n",
    "# Model was trained with log1p(count)\n",
    "# So, we need to apply inverse transformation to get the actual count\n",
    "# Predicted Count looks much better now\n",
    "result = predictor.predict(transform_data(sample_one))\n",
    "result = result.decode(\"utf-8\")\n",
    "print ('Predicted Count', math.expm1(float(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to send multiple samples\n",
    "result = predictor.predict([transform_data(sample_one), transform_data(sample_two)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.349300861358643,6.321451187133789'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Prediction\n",
    "# Transform data and invoke prediction in specified batch sizes\n",
    "def run_predictions(data, batch_size):\n",
    "    predictions = []\n",
    "    \n",
    "    transformed_data = [transform_data(row.strip()) for row in data]\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        \n",
    "        print(i,i+batch_size)\n",
    "        \n",
    "        result = predictor.predict(transformed_data[i : i + batch_size])\n",
    "        \n",
    "        result = result.decode(\"utf-8\")\n",
    "        result = result.split(',')\n",
    "        \n",
    "        predictions += [math.expm1(float(r)) for r in result]\n",
    "                \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[571.092597122044, 555.3798181158465, 10.489585991183136]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_predictions([sample_one,sample_two,sample_three],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a batch prediction on Test.CSV File\n",
    "# Read the file content\n",
    "data = []\n",
    "with open('test.csv','r') as f:\n",
    "    # skip header\n",
    "    f.readline()\n",
    "    # Read remaining lines\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 500\n",
      "500 1000\n",
      "1000 1500\n",
      "1500 2000\n",
      "2000 2500\n",
      "2500 3000\n",
      "3000 3500\n",
      "3500 4000\n",
      "4000 4500\n",
      "4500 5000\n",
      "5000 5500\n",
      "5500 6000\n",
      "6000 6500\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = run_predictions(data,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6493, 6493)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions),len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to delete the endpoint\n",
    "# From SageMaker Console, Select \"Endpoints\" under Inference and Delete the Endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
